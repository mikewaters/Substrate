---
tags:
  - document ðŸ“‘
---
# Local Inference Engines

Ollama, cortex.cpp, LMStudio, Llama.cpp etc

[Homelab Decisions.md](./Homelab%20Decisions.md): Using LM Studio, due to its great support for Metal/MLX Nov 10, 2025


